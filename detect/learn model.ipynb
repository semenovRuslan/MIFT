{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# additional function\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "from sklearn.externals import joblib\n",
    "# To read file names\n",
    "import argparse as ap\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#Normalize\n",
    "#L1\n",
    "#L1-sqrt\n",
    "#L2\n",
    "#L2-Hys\n",
    "\n",
    "min_wdw_sz =[64, 128]\n",
    "step_size = [8, 8]\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (4, 4)\n",
    "visualize = False\n",
    "normalize = True\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "def hogMy(im, orientations, pixels_per_cell, cells_per_block, visualize, normalize): \n",
    "    fd = hog(im, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualise=visualize,\n",
    "            block_norm= \"L1\", transform_sqrt=False, feature_vector=True)\n",
    "    hog_features = np.array(fd, 'float64')\n",
    "    \n",
    "    # Normalize the features\n",
    "    pp = preprocessing.StandardScaler().fit(hog_features)\n",
    "    hog_features = pp.transform(hog_features)\n",
    "    \n",
    "    return hog_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utilsDetect#; reload(utilsDetect)\n",
    "from utilsDetect import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sourceFile = \"TA/shop1.jpg\"\n",
    "\n",
    "pos_source = \"train/positive\"\n",
    "neg_source = \"train/negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "import argparse as ap\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "full_data=[]\n",
    "full_label=[]\n",
    "\n",
    "# Load the positive features\n",
    "for feat_path in glob.glob(os.path.join(pos_source,\"*\")):\n",
    "    im = imread(feat_path, as_grey=True)\n",
    "    #im=resizeImage(im)\n",
    "    fd = hogArray(im, orientations, pixels_per_cell, cells_per_block, visualize, normalize)\n",
    "    full_data.append(fd)\n",
    "    full_label.append(1)\n",
    "\n",
    "# Load the negative features\n",
    "for feat_path in glob.glob(os.path.join(neg_source,\"*\")):\n",
    "    im = imread(feat_path, as_grey=True)\n",
    "    im=resizeImage(im)\n",
    "    fd = hogArray(im, orientations, pixels_per_cell, cells_per_block, visualize, normalize)\n",
    "    full_data.append(fd)\n",
    "    full_label.append(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets, linear_model, metrics, cross_validation \n",
    "\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "#split data\n",
    "train_data, test_data, train_label, test_label = cross_validation.train_test_split(\n",
    "    full_data, full_label, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8626506024096385\n",
      "f1: 0.5488126649076517\n",
      "[[ 0.01342673 -0.03837251 -0.0002492  ..., -0.01950641  0.03474442\n",
      "   0.01409306]]\n",
      "[-0.96757419]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train/svmLinearClassifier.model']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"train/svmLinearClassifier.model\"\n",
    "\n",
    "#создаем классификатора\n",
    "ridge_classifier = linear_model.RidgeClassifier(random_state=1)\n",
    "# обучим модель для этого передадим обучающую выборку и метки классов\n",
    "ridge_classifier.fit(train_data, train_label)\n",
    "# теперь можем строить наши предсказания:\n",
    "ridge_prediction=ridge_classifier.predict(test_data)\n",
    "\n",
    "# формально оценим качество модели при помощи accuracy:\n",
    "print('accuracy: {}'.format(metrics.accuracy_score(test_label, ridge_prediction)))\n",
    "print('f1: {}'.format(metrics.f1_score(test_label, ridge_prediction)))\n",
    "# кроме качества обучения  мы можем смотреть на веса признаков \n",
    "print (ridge_classifier.coef_)\n",
    "# свободный коеффициент. Коэффициент перед свободным членом\n",
    "print (ridge_classifier.intercept_)\n",
    "\n",
    "\n",
    "#save model\n",
    "joblib.dump(ridge_classifier, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liner Model Default\n",
    "\n",
    "this model have got in example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Linear SVM Classifier\n",
      "accuracy: 0.9060240963855422\n",
      "f1: 0.5682656826568266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train/svm.model']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "print (\"Training a Linear SVM Classifier\")\n",
    "clf.fit(train_data, train_label)\n",
    "# теперь можем строить наши предсказания:\n",
    "clf_prediction=clf.predict(test_data)\n",
    "# формально оценим качество модели при помощи accuracy:\n",
    "print('accuracy: {}'.format(metrics.accuracy_score(test_label, clf_prediction)))\n",
    "print('f1: {}'.format(metrics.f1_score(test_label, clf_prediction)))\n",
    "\n",
    "#save model\n",
    "joblib.dump(clf, \"train/svm.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845896147404\n",
      "0.406451612903\n",
      "Regression saved to train/svmLinearRegression.model\n"
     ]
    }
   ],
   "source": [
    "model_path = \"train/svmLinearRegression.model\"\n",
    "\n",
    "log_regressor=linear_model.LogisticRegression(random_state=1)\n",
    "#обучаем модель\n",
    "log_regressor.fit(train_data, train_label)\n",
    "#прогнозируем\n",
    "log_predict=log_regressor.predict(test_data)\n",
    "# regression вероятностный метод поэтому каждый ответ имеет некую вероятностную составляющую\n",
    "log_predict_probability = log_regressor.predict_proba(test_data)\n",
    "#оценим\n",
    "print ('accuracy: {}'.format(metrics.accuracy_score(log_predict, test_label)))\n",
    "print ('f1: {}'.format(metrics.f1_score(log_predict, test_label)))\n",
    "\n",
    "\n",
    "#save model\n",
    "joblib.dump(log_regressor, model_path)\n",
    "print (\"Regression saved to {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9307253463732681\n",
      "f1: 0.5502645502645502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train/svmRandomF.model']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"train/svmRandomF.model\"\n",
    "#модель случайный лес\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import pipeline, preprocessing\n",
    "from sklearn import metrics \n",
    "\n",
    "#classifier = RandomForestClassifier(random_state=0, \n",
    "                               # max_depth=2, \n",
    "                               #   n_estimators=50)\n",
    "classifier = RandomForestClassifier(random_state=0, \n",
    "                                    min_samples_split=5, \n",
    "                                    n_estimators=50)\n",
    "\n",
    "\n",
    "#обучим\n",
    "classifier.fit(train_data, train_label)\n",
    "\n",
    "clf_prediction=classifier.predict(test_data)\n",
    "# формально оценим качество модели при помощи accuracy:\n",
    "print('accuracy: {}'.format(metrics.accuracy_score(test_label, clf_prediction)))\n",
    "print('f1: {}'.format(metrics.f1_score(test_label, clf_prediction)))\n",
    "\n",
    "#save model\n",
    "joblib.dump(classifier, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametrize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8850855745721271\n",
      "f1: 0.5791044776119403\n"
     ]
    }
   ],
   "source": [
    "# модель с параметрами по умолчанию\n",
    "ClassifierDefault = linear_model.SGDClassifier(random_state=0)\n",
    "ClassifierDefault.fit(train_data, train_label)\n",
    "#прогнозируем\n",
    "cd_predict=ClassifierDefault.predict(test_data)\n",
    "#оценим\n",
    "print ('accuracy: {}'.format(metrics.accuracy_score(cd_predict, test_label)))\n",
    "print ('f1: {}'.format(metrics.f1_score(cd_predict, test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['verbose', 'warm_start', 'l1_ratio', 'shuffle', 'eta0', 'n_jobs', 'random_state', 'fit_intercept', 'average', 'power_t', 'alpha', 'epsilon', 'penalty', 'class_weight', 'learning_rate', 'loss', 'n_iter'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import cross_validation, grid_search\n",
    "\n",
    "#эту же модель настроим через сетку\n",
    "ClassifierCustom = linear_model.SGDClassifier(random_state=0)\n",
    "ClassifierCustom.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create parametric matrix \n",
    "# по имеющимся в модели параметрам мы записываем возможные значения перебирая которые \n",
    "# определим лучшую модель методом перебора\n",
    "parameters_grid ={\n",
    "    'loss':['hinge', 'log', 'squared_hinge', 'squared_loss'],\n",
    "    'penalty':['l1', 'l2'],\n",
    "    'n_iter': [5, 6, 7, 8, 9, 10],\n",
    "    'alpha': np.linspace(0.0001, 0.001, num=5),\n",
    "}\n",
    "\n",
    "#создаем стратегию cross-validation\n",
    "cv=cross_validation.StratifiedShuffleSplit(train_label, test_size=0.2, n_iter=10, random_state=0)\n",
    "\n",
    "#создаем объект gridsearch, который будет искать по метрике \"ACCURACY\" лучшие параметры\n",
    "grid_cv=grid_search.GridSearchCV(ClassifierCustom, parameters_grid, scoring='accuracy', cv=cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(labels=[0 0 ..., 0 0], n_iter=10, test_size=0.2, random_state=0),\n",
       "       error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "       warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([ 0.0001 ,  0.00032,  0.00055,  0.00078,  0.001  ]), 'n_iter': [5, 6, 7, 8, 9, 10], 'loss': ['hinge', 'log', 'squared_hinge', 'squared_loss'], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_cv.fit(train_data, train_label)\n",
    "# далее обучаем сетку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=10, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получить лучший классификатор:\n",
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9413654618473896\n",
      "f1: 0.7474048442906573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train/svmBestSGD.model']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path=\"train/svmBestSGD.model\"\n",
    "#построим модель при этом возьмем те параметры которые\n",
    "# мы уже подобрали в прошлую попытку как оптимальные при наших данных\n",
    "# {'regression__n_iter': 3, 'regression__loss': 'squared_loss', \n",
    "# 'scaling__with_mean': 0, 'regression__alpha': 0.01, \n",
    "# 'regression__penalty': 'l2'}\n",
    "\n",
    "bestSGD = linear_model.SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
    "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
    "       learning_rate='optimal', loss='hinge', n_iter=10, n_jobs=1,\n",
    "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
    "       warm_start=False)\n",
    "#обучим\n",
    "bestSGD.fit(train_data, train_abel)\n",
    "#прогнозируем\n",
    "cd_predict=bestSGD.predict(test_data)\n",
    "#оценим\n",
    "print ('accuracy: {}'.format(metrics.accuracy_score(cd_predict, test_label)))\n",
    "print ('f1: {}'.format(metrics.f1_score(cd_predict, test_label)))\n",
    "\n",
    "#save model\n",
    "joblib.dump(bestSGD, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
